# Whisper
**作成日**: 2025年7月2日

---

## 📝 概要
WhisperはOpenAIが開発した音声認識モデル。API経由だけでなく、ローカルにモデルをダウンロードして単体で音声をテキスト化できる。ネット不要でプライバシー性が高く、アプリケーションに組み込んで自由に使えるのが特徴。

---

## 🔎 どんな使い方がある？
- **CLI単体利用**  
  - ターミナルで音声ファイルを直接文字起こし。
  - 例:
    ```bash
    whisper myaudio.mp3 --model medium
    ```
  - テキストファイルとして出力される。

- **自作アプリやスクリプトに組み込み**
  - 録音後の音声データをWhisperに渡し、テキスト化してUIに反映。
  - Pythonなら公式ライブラリ、macOSアプリなどはwhisper.cppをC++やSwiftから呼び出すパターンが多い。

---

## 💡 代表的な実装
- [openai/whisper](https://github.com/openai/whisper)
  - 公式のPython実装。
  - モデルサイズを選んで精度と速度を調整できる。
- [ggerganov/whisper.cpp](https://github.com/ggerganov/whisper.cpp)
  - C++移植版。
  - 軽量かつ爆速。Appleシリコンやラズパイでも動く。

---

## 📦 どんなときに使われる？
- ボイスメモやインタビューの文字起こし
- 動画字幕生成
- アプリの音声入力機能
- プライバシーを守りたい現場（医療、法務など）でローカル処理として活用

---

## ✅ まとめ
Whisperはローカルで完結する音声認識ソリューションとして非常に柔軟。GitHubで公開されているアプリや自作ツールにくっつけて使われるのが一般的で、APIなし運用も十分実用的。

---
